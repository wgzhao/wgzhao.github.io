<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux技术 | Linux系统管理]]></title>
  <link href="http://wgzhao.github.io/blog/categories/linuxji-zhu/atom.xml" rel="self"/>
  <link href="http://wgzhao.github.io/"/>
  <updated>2014-03-14T14:19:10+08:00</updated>
  <id>http://wgzhao.github.io/</id>
  <author>
    <name><![CDATA[wgzhao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Linux下的一些I/O统计工具]]></title>
    <link href="http://wgzhao.github.io/2012/08/22/some-way-to-io-statistics-on-linux/"/>
    <updated>2012-08-22T10:25:00+08:00</updated>
    <id>http://wgzhao.github.io/2012/08/22/some-way-to-io-statistics-on-linux</id>
    <content type="html"><![CDATA[<p>作为一个Linux系统管理员，统计各类IO是一项必不可少的工作。其统计工具中iostat显然又是最重要的一个统计手段。但是这里iostat不是本文的重点，因为这个工具的使用在网络上已经有大量的教程，可以供大家参考。这里主要是想介绍一些其他统计工具以来满足不同的需求。</p>

<h3>iostat</h3>

<p>iostat的功能异常强大，输出项也特别多，比如下面这个例子：</p>

<p>```
Device: rrqm/s  wrqm/s  r/s     w/s    rkB/s    wkB/s    avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</p>

<p>sda     0.00     0.50  173.50   73.50  3076.00   604.00    29.80   149.93    676.58   74.36 2098.15  4.05 100.00
```</p>

<p>其各项的含义分别是：</p>

<!--more-->


<ul>
<li>rrqm/s:       每秒进行 merge 的读操作数目.即 delta(rmerge)/s</li>
<li>wrqm/s:  每秒进行 merge 的写操作数目.即 delta(wmerge)/s</li>
<li>r/s:               每秒完成的读 I/O 设备次数.即 delta(rio)/s</li>
<li>w/s:             每秒完成的写 I/O 设备次数.即 delta(wio)/s</li>
<li>rsec/s:        每秒读扇区数.即 delta(rsect)/s</li>
<li>wsec/s:      每秒写扇区数.即 delta(wsect)/s</li>
<li>rkB/s:          每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算)</li>
<li>wkB/s:    每秒写K字节数.是 wsect/s 的一半.(需要计算)</li>
<li>avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio)</li>
<li>avgqu-sz: 平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒).</li>
<li>await:        平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio)</li>
<li>svctm:       平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio)</li>
<li>%util:          一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的.即 delta(use)/s/1000 (因为use的单位为毫秒)</li>
</ul>


<p>如果 <code>%util</code> 接近 100%,说明产生的I/O请求太多,I/O系统已经满负荷,该磁盘可能存在瓶颈.</p>

<p>idle小于70% IO压力就较大了,一般读取速度有较多的wait.</p>

<p>同时可以结合<code>vmstat</code>查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比,高过30%时IO压力高)</p>

<p>另外 <code>await</code> 的参数也要多和 <code>svctm</code> 来参考。差的过高就一定有 IO 的问题.</p>

<p><code>avgrq-sz</code> 也是个做 IO 调优时需要注意的地方,这个就是直接每次操作的数据的大小,如果次数多,但数据拿的小的话,其实 IO 也会很小.如果数据拿的大,才IO 的数据会高.也可以通过 <code>avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s</code>.也就是讲,读定速度是这个来决定的.</p>

<p><code>svctm</code> 一般要小于 <code>await</code> (因为同时等待的请求的等待时间被重复计算了),<code>svctm</code> 的大小一般和磁盘性能有关,CPU/内存的负荷也会对其有影响,请求过多也会间接导致 <code>svctm</code> 的增加.<code>await</code> 的大小一般取决于服务时间(<code>svctm</code>) 以及 I/O 队列的长度和 I/O 请求的发出模式.如果 svctm 比较接近 await,说明 I/O 几乎没有等待时间；如果 await 远大于 svctm,说明 I/O 队列太长,应用得到的响应时间变慢,如果响应时间超过了用户可以容许的范围,这时可以考虑更换更快的磁盘,调整内核 <code>elevator</code> 算法,优化应用,或者升级 CPU.</p>

<p> 队列长度(<code>avgqu-sz</code>)也可作为衡量系统 I/O 负荷的指标,但由于 <code>avgqu-sz</code> 是按照单位时间的平均值,所以不能反映瞬间的 I/O 洪水.</p>

<p>有时间的话，我会单独写几个帖子来说说<code>iostat</code>。</p>

<h3>iodump</h3>

<p><a href="http://aspersa.googlecode.com/svn/trunk/iodump">iodump</a> 是一个统计每一个进程(线程)所消耗的磁盘I/O工具。这个一个perl脚本，其原理时打开有关I/O的内核记录消息开关，而后读取消息然后分析输出。简单使用步骤如下：</p>

<p>首先下载这个工具</p>

<p><code>wget http://aspersa.googlecode.com/svn/trunk/iodump</code></p>

<p>然后打开有关I/O内核消息的开关</p>

<p><code>echo 1 &gt;/proc/sys/vm/block_dump</code></p>

<p>上述开关打开后，内核会记录下每一个I/O操作的消息。我们只需要定时获取并分析就好了，比如下面这样</p>

<p><code>while true; do sleep 1; dmesg -c ; done |perl iodump</code></p>

<p>等待一段时间，然后通过<code>ctrl+c</code>来结束上述脚本，你将获得下面类似的信息:</p>

<p><code>
TASK                   PID      TOTAL       READ      WRITE      DIRTY DEVICES
postgres              5799       1919       1919          0          0 sda7
jbd2/sda7-8           1572         35          0         35          0 sda7
jbd2/sda2-8            250         32          0         32          0 sda2
flush-8:0             2229         31          0         31          0 sda2, sda7
postgres              4308          2          0          2          0 sda7
bash                  5804          1          0          1          0 sda2
</code>
上述输出的单位为块(block)，每块的大小取决于创建文件系统时指定的块大小。比如我这个里的sda7的block大小是1KB。</p>

<h3>iotop</h3>

<p><a href="http://guichaz.free.fr/iotop/">iotop</a>是一个Python编写的工具，有类似<code>top</code>工具的UI，包括一些参数也和<code>top</code>类似。不过它对系统有一些要求，分别是：</p>

<ol>
<li>Python ≥ 2.5 or Python ≥  2.4 with the ctypes module</li>
<li>Kernel ≥  2.6.20</li>
<li>Kernel uses options:

<ol>
<li>TASK_DELAY_ACCT</li>
<li>CONFIG_TASKSTATS</li>
<li>TASK_IO_ACCOUNTING</li>
<li>CONFIG_VM_EVENT_COUNTERS</li>
</ol>
</li>
</ol>


<p>如果是基于RPM包的系统，可以直接下载编译好的二进制包(<a href="http://guichaz.free.fr/iotop/files/iotop-0.4.4-1.noarch.rpm">here</a>)或者二进制源代码包(<a href="http://guichaz.free.fr/iotop/files/iotop-0.4.4-1.src.rpm">here</a>)</p>

<p>如果是Debian/Ubuntu系统，直接使用</p>

<p><code>sudo apt-get install iotop</code></p>

<p>即可（不得不说，Debian系统提供的软件真的是相当丰富呀)，其他系统则可以通过下面的指令下载源代码，然后编译</p>

<p><code>git clone git://repo.or.cz/iotop.git</code></p>

<p>具体的使用方法可以参考iotop(8)手册，下面是在我机器上的一个显示：</p>

<p><code>
iotop -o -u wgzhao
Total DISK READ:       2.15 M/s | Total DISK WRITE:    1601.15 K/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN      IO    COMMAND
 5984 be/4 wgzhao      2.15 M/s   70.55 K/s  0.00 % 83.67 % postgres: wgzhao pgbench [local] UPDATE
 4305 be/4 wgzhao      0.00 B/s  227.34 K/s  0.00 %  0.00 % postgres: writer process
 4308 be/4 wgzhao      0.00 B/s   90.15 K/s  0.00 %  0.00 % postgres: stats collector process
</code></p>

<h3>iopp</h3>

<p><a href="https://github.com/markwkm/iopp">iopp</a>是另外一个统计每一个进程I/O的工具，使用C语言编写，理论上应该比上述两个重狙效率都要高。<br/>
安装方法很简单，首先通过下面的指令下载源代码:</p>

<p><code>git://github.com/markwkm/iopp.git</code></p>

<p>然后分别通过下面的指令编译安装</p>

<p><code>
cmake CMakeLists.txt
make
make install DESTDIR=/usr
</code></p>

<p>下面是一个使用例子</p>

<p><code>
iopp -i -c 2
  pid    rchar    wchar    syscr    syscw   rbytes   wbytes  cwbytes command
 2144        0      296       40        8        0        0        0 /usr/sbin/LCDd
 2284        0        0        2        0        0        0        0 ha_logd: read process
 2299        0        0        2        0        0        0        0 ha_logd: write process
 2520        3        3        3        3        0        0        0 /usr/lib/virtualbox/vboxwebsrv
 2599        2        2        2        2        0        0        0 /usr/lib/virtualbox/VBoxSVC
 2675        0        0        1        0        0        0        0 runsvdir
 3177       16       16        4        2        0        0        0 /usr/bin/gnome-shell
 3192       16       16        4        2        0        0        0 nautilus
 3305      180      340      100       60        0        0        0 /usr/lib/icedove/icedove-bin
 3623     1393     1440        1        1        0        0        0 sshd: wgzhao@pts/0
 4305        0  4603904        0      562        0  4603904        0 postgres: writer process   
 6257  2064384  1892352      252      215  3719168   139264        0 postgres: wgzhao pgbench [local] UPDATE
</code></p>

<p>上述输出的各项含义是：</p>

<ul>
<li>pid 进程ID</li>
<li>rchar 将要从磁盘读取的字节数</li>
<li>wchar 已经写入或应该要写入磁盘的字节数</li>
<li>syscr 读I/O数</li>
<li>syscw 写I/O数</li>
<li>rbytes 真正从磁盘读取的字节数</li>
<li>wbytes 真正写入到磁盘的字节数</li>
<li>cwbytes 因为清空页面缓存而导致没有发生操作的字节数</li>
<li>command 执行的命令</li>
</ul>


<p>其中<code>rbytes</code>,<code>wbytes</code>,<code>cwbytes</code>会因给出<code>-k</code>或者<code>-m</code>参数，而显示为<code>rkb</code>,<code>wkb</code>,<code>cwkb</code>或<code>rmb</code>,<code>wmb</code>,<code>cwmb</code>。<code>command</code>一列如果给出<code>-c</code>的参数则显示完整的命令名而不仅仅只是命令本身。<br/>
这些参数的使用和<code>top</code>类似。</p>

<p>更具体的可以参考iopp(8)手册。</p>

<h3>dstat</h3>

<p><a href="http://dag.wieers.com/home-made/dstat/">dstat</a> 号称各种资源统计工具，其目的是想替代<code>vmstat</code>,<code>iostat</code>,<code>netstat</code>,<code>ifstat</code>等各种单一统计工具，从而做到<code>All in one</code>。 dstat用Python语言编写。</p>

<p>dstat能够清晰显示每列的信息，特别是单位及大小很明确，不会在单位换算上犯迷糊和失误。最重要的是，因为它是基于模块化设计，因此我们可以很容易的写一个插件来收集我们需要的统计信息。</p>

<p>另外，dstat的输出还可以导出为<code>CSV</code>格式文件，从而可以在电子表格工具里分方便的生成统计图形。</p>

<p>目前dstat的插件已经相当多了，这是我机器上目前的输出:</p>

<p>```
$ dstat  &mdash;list
internal:</p>

<pre><code>aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock, mem, net, 
page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix, vm
</code></pre>

<p>/usr/share/dstat:</p>

<pre><code>battery, battery-remain, cpufreq, dbus, disk-tps, disk-util, dstat, dstat-cpu, dstat-ctxt, 
dstat-mem, fan, freespace, gpfs, gpfs-ops, helloworld, innodb-buffer, innodb-io, innodb-ops, lustre, 
memcache-hits, mysql-io, mysql-keys, mysql5-cmds, mysql5-io, mysql5-keys, net-packets, nfs3, 
nfs3-ops, nfsd3, nfsd3-ops, ntp, postfix, power, proc-count, qmail, rpc, rpcd, sendmail, snooze, 
squid, test, thermal, top-bio, top-bio-adv, top-childwait, top-cpu, top-cpu-adv, top-cputime, 
top-cputime-avg, top-int, top-io, top-io-adv, top-latency, top-latency-avg, top-mem, top-oom, utmp, 
vm-memctl, vmk-hba, vmk-int, vmk-nic, vz-cpu, vz-io, vz-ubc, wifi
</code></pre>

<p>```</p>

<p>下面给出几个使用的列子（实际输出是带彩色的，很容易识别）</p>

<p>dstat的缺省输出</p>

<p><code>
wgzhao-nb:~# dstat
You did not select any stats, using -cdngy by default.
----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw
  2   1  87  10   0   0| 816k  385k|   0     0 |   0     0 |2279  7048
  5   1  78  16   0   0|2600k    0 | 140B  940B|   0     0 |5952    13k
  5   3  80  12   0   0|2896k  182k|  70B  358B|   0     0 |6074    14k
  4   2  78  16   0   0|2724k    0 |  70B  374B|   0     0 |5703    15k
  4   2  81  14   0   0|3008k    0 |  70B  358B|   0     0 |5924    13k
  5   1  80  14   0   0|1976k   17k|  70B  358B|   0     0 |5819    13k
  5   2  79  14   0   0|2056k    0 | 198B  374B|   0     0 |5618    13k
  4   2  79  15   0   0|2416k    0 |  70B  358B|   0     0 |5866    15k
  5   2  78  15   0   0|2528k    0 |  70B  358B|   0     0 |6356    14k
  5   2  78  16   0   0|2288k    0 |  70B  358B|   0     0 |6515    15k
  5   2  79  14   0   0|2656k 8192B|  70B  358B|   0     0 |6490    15k
  3   2  81  13   0   0|2296k    0 |  70B  374B|   0     0 |5573    15k
  4   3  76  17   0   1|2224k    0 |  70B  358B|   0     0 |5366    12k
  5   1  81  13   0   0|2208k    0 | 508B  358B|   0     0 |5403    13k
  4   2  79  15   0   0|2024k  182k|  70B  358B|   0     0 |5583    13k
  5   2  79  15   0   0|2148k   17k| 186B  490B|   0     0 |5400    12k
</code></p>

<p>指定需要显示的列</p>

<p><code>
wgzhao-nb:~# dstat  -c --top-cpu -d --top-bio --top-latency
Module dstat_top_latency failed to load. (Kernel has no scheduler statistics, use at least 2.6.12)
----total-cpu-usage---- -most-expensive- -dsk/total- ----most-expensive----
usr sys idl wai hiq siq|  cpu process   | read  writ|  block i/o process   
  2   1  87  10   0   0|gnome-shell  0.7| 826k  384k|postgres    692k   52k
  4   2  79  16   0   0|postgres: wgz3.0|1744k  776k|postgres: w1744k   72k
  5   3  78  15   0   0|postgres: wgz5.0|3120k    0 |postgres: w3064k  136k
  6   2  73  19   0   0|postgres: wgz4.2|2608k  285k|postgres: w2608k  136k
  4   2  77  17   0   0|postgres: wgz3.5|2112k  848k|postgres: w2112k   88k
  3   2  71  25   0   0|postgres: wgz2.0| 944k 1049k|postgres: w 936k   48k
  3   2  58  37   0   0|postgres: wgz2.0| 920k 2070k|postgres: w 928k   64k
  3   2  62  34   0   0|postgres: wgz2.2|1496k  992k|postgres: w1608k   72k
  3   2  56  38   0   0|postgres: wgz3.0|1840k  645k|postgres: w1856k   88k
  3   2  78  17   0   0|postgres: wgz3.0|1420k 1200k|postgres: w1292k   80k
  5   2  80  12   0   1|postgres: wgz4.2|2628k    0 |postgres: w2636k  112k
  4   3  69  25   0   0|postgres: wgz3.8|2168k  576k|postgres: w2224k  104k
</code></p>

<p>指定需要显示的列，并同时将结果导出到文件</p>

<p><code>
wgzhao-nb:~# dstat  --disk --mem --proc --io --sys --filesystem --tcp --vm --output dstat.csv
-dsk/total- ------memory-usage----- ---procs--- --io/total- ---system-- --filesystem- ----tcp-sockets---- -----virtual-memory----
 read  writ| used  buff  cach  free|run blk new| read  writ| int   csw |files  inodes|lis act syn tim clo|majpf minpf alloc  free
 844k  404k| 829M 19.4M 2920M  124M|  0 0.0 0.7|47.5  38.4 |2336  7185 | 4928  12286 | 11   3   0   0   2|   1   620   602   605
2128k 1526k| 828M 19.4M 2915M  130M|  0 2.0   0| 111   157 |4588    14k| 4928  12285 | 11   3   0   0   2|   0  1859   995  2278
 920k 2151k| 826M 19.4M 2917M  129M|  0 2.0   0|52.0   237 |3091  7540 | 4928  12284 | 11   3   0   0   2|   0  4448  2330  2144
2124k 1003k| 826M 19.4M 2921M  126M|1.0 1.0   0| 135   106 |4705    14k| 4928  12284 | 11   3   0   0   2|   0   331   865     1
2344k 1024k| 826M 19.4M 2924M  122M|1.0 2.0   0| 121   118 |4074    13k| 4928  12284 | 11   3   0   0   2|   0   249   953     1
1572k 1624k| 827M 19.4M 2926M  120M|1.0 2.0   0|87.0   190 |3231    11k| 4928  12284 | 11   3   0   0   2|   0    98   530     1
 916k  788k| 827M 19.4M 2928M  119M|  0 2.0   0|68.0  92.0 |3452  8709 | 4928  12284 | 11   3   0   0   2|   0   128   383     4
2452k 1665k| 826M 19.4M 2931M  116M|1.0 1.0   0| 132   197 |4779    14k| 4928  12284 | 11   3   0   0   2|   0   208   822     1
1552k 1328k| 827M 19.4M 2933M  114M|  0 2.0   0|97.0   156 |3762  9117 | 4928  12284 | 11   3   0   0   2|   0   133   473     1
1192k 2024k| 827M 19.4M 2934M  112M|  0 2.0   0|81.0   239 |4068    11k| 4928  12284 | 11   3   0   0   2|   0   135   414     2
2668k  584k| 827M 19.4M 2937M  109M|  0 2.0   0| 148  71.0 |4415    10k| 4928  12284 | 11   3   0   0   2|   0   174   870     4
1712k  960k| 827M 19.4M 2940M  106M|  0 2.0   0| 122   113 |4454    14k| 4928  12284 | 11   3   0   0   2|   0   182   616     2
</code></p>

<p>更详细的用法，可以参考dstat(1)手册</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[用sfex资源脚本来防止HA脑裂后共享磁盘数据被损坏的风险]]></title>
    <link href="http://wgzhao.github.io/2012/01/12/heartbeat-prevent-from-destruction-of-data-on-shared-disk-due-to-split-brain-by-using-sfex-resource-agent/"/>
    <updated>2012-01-12T14:53:00+08:00</updated>
    <id>http://wgzhao.github.io/2012/01/12/heartbeat-prevent-from-destruction-of-data-on-shared-disk-due-to-split-brain-by-using-sfex-resource-agent</id>
    <content type="html"><![CDATA[<p>在<a href="http://zh.wikipedia.org/wiki/HA" title="High Availability">HA</a>部署众,心跳无疑是最重要的组件，因此心跳也绝大部分你情况是冗余的，大部分都是用网络做心跳介质，因此一般认为是可靠的。但是，所有的事情都有意外，如果心跳出现了故障，到时<a href="http://zh.wikipedia.org/wiki/HA" title="High Availability">HA</a>环境中的节点互相直接之间无法通信，就会出现脑裂(Split Brain)现象，出现这种情况后，会导致<a href="http://zh.wikipedia.org/wiki/HA" title="High Availability">HA</a>监控的服务会在多个节点上同时运行，如果此时有共享存储，则会导致共享存储在多个节点上同时可写挂载，从而导致文件系统崩溃，数据丢失。这显然不是可以接受的情况。</p>

<!--more-->


<p>开源<a href="http://zh.wikipedia.org/wiki/HA" title="High Availability">HA</a>解决方案&mdash;<a href="http://linux-ha.org/wiki/Heartbeat" title="Heartbeat">Heartbeat</a>&mdash;解决这个问题的方案是使用成为<a href="http://linux-ha.org/wiki/Fencing" title="Fencing">Fence</a>的设备，也就是电源管理设备，当发生脑裂情况时，<a href="http://linux-ha.org/wiki/Heartbeat" title="Heartbeat">Heartbeat</a>通知电源设备关闭该节点。目前绝大部分服务器都自带了这样的设备。</p>

<p>虽然都自带了，但我必须承认，到目前为止，我真的还没有在<a href="http://linux-ha.org/wiki/Heartbeat" title="Heartbeat">Heartbeat</a>上部署过。我也一直在找一个靠谱的纯软件解决方案。这几天测试了<a href="http://linux-ha.org/wiki/Heartbeat" title="Heartbeat">Heartbeat</a>自带的<a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a> 工具，发现基本上可以帮我们防止因脑裂带来的共享磁盘存在数据解构的风险。<a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a>的原理是在一个独立的共享存储上的一个分区上写上锁信息，在一个分区上可以有多个锁信息（通过sfex_init -n 来指定），每一个锁信息可以对应一个数据分区。然后把Filesystem资源配置为依赖<a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a>资源，这样每次需要挂载数据分区时，都需要预先去读取锁信息，如果能获得锁信息，则可以挂载，否则不能挂载。</p>

<h2>基本概念</h2>

<ul>
<li><a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a>,即Shared Disk File EXclusiveness Control Pogram，被定位一种<a href="http://www.linux-ha.org/wiki/OCF_Resource_Agents" title="Open Cluster Framework">OCF</a>资源，用于控制共享磁盘的所有权。</li>
<li><a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a> 在共享磁盘上使用一个特定的分区,用来维护下列数据:

<ul>
<li>&ldquo;status&rdquo; 显示当前共享磁盘属于谁?</li>
<li>&ldquo;node&rdquo; 显示所有权节点名称</li>
<li>&ldquo;count&rdquo; 用于判断拥有者节点是否运行</li>
</ul>
</li>
<li>通常把使用共享存储上的数据分区的资源(比如PostgreSQL)和<a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a>配置在一个组资源里</li>
<li>所有权节点可以访问数据分区</li>
</ul>


<p><img src="http://farm8.staticflickr.com/7023/6683231303_e3e2eef26b.jpg" alt="sfex0" /></p>

<ul>
<li>什么时候可以获得所有权

<ul>
<li>无人有所有权</li>
<li>节点能够判断另外一个节点已经宕机</li>
</ul>
</li>
</ul>


<h2>时序图</h2>

<h3>启动过程</h3>

<p><a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a>可以在分值最高的节点上运行，此时，其他节点则无法同时访问共享存储（无法获得锁)</p>

<h4>Node A</h4>

<ol>
<li>SFEX 从共享存储上读取数据从而获得"status"，通常"status"是"NO_OWNED"，表示当前没有节点有所有权。</li>
<li>写数据到共享存储，内容包括"node=Node A" 和"status=OWNED"</li>
<li>重读数据,获得"node=Node A"</li>
<li>比较节点名是不是和当前节点一致,如果节点名没有改变,则Node A获得所有权</li>
<li>SFEX 在监控共享存储的过程中增加"count"值,表明所有权节点在线</li>
</ol>


<p><img src="http://farm8.staticflickr.com/7008/6683231135_abcd4efb32.jpg" alt="sfex_seq4_st_access" /></p>

<h3>心跳通信失败</h3>

<h4>Node A</h4>

<ol>
<li>SFEX 通过心跳监控进程更新所有权</li>
</ol>


<h4>Node B</h4>

<ol>
<li>当心跳通信失败时,待命(stand by)节点(Node B)开始启动资源</li>
<li>SFEX 从共享存储上读取数据</li>
<li>等待一会儿，等待时间应该长于sfex监控间隔(interval)，在等待期间，它定期等待Node A的更新，以确保Node A 还在维护所有权</li>
<li>重新读取数据</li>
<li>检查"count"的新值，当两个"count"有差别时，它会认为Node A 还在线</li>
<li>SFEX 启动进程停止</li>
</ol>


<p><img src="http://farm8.staticflickr.com/7163/6683230921_b70a739c6d.jpg" alt="sfex_seq3_nodedown" /></p>

<h3>活动节点失效</h3>

<h4>Node A</h4>

<ol>
<li>Node A 失效</li>
</ol>


<h4>Node B</h4>

<ol>
<li>等待一会，等待Node A 定期更新，但此时发现Node A 没有更新</li>
<li>SFEX 重新读取数据</li>
<li>检查"count"的新值，发现两个值相同，于是它认为Node A 已经失效了(down)</li>
<li>写数据到共享存储，内容包括"node=Node B" 和 &ldquo;status=OWNED&rdquo;</li>
<li>重读数据,获得"node=Node B"</li>
<li>比较节点名是不是和当前节点一致,如果节点名没有改变,则Node B获得所有权</li>
<li>然后启动后续资源</li>
</ol>


<p><img src="http://farm8.staticflickr.com/7169/6683230701_2bf943a5b7.jpg" alt="sfex_seq2_hbdown" /></p>

<h2>配置步骤</h2>

<h3>创建特定分区</h3>

<p>首先,需要在共享存储上划出一个单独的小分区出来,不用多大,一个节点仅需要1Kb。因此100M足够了。假定是<code>/dev/sdb1</code>。</p>

<h3>初始化</h3>

<p><a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a>提供了<code>sfex_init</code>指令来初始化特定分区，使用方式如下<br/>
<code>sfex_init -n 2 /dev/sdb1</code><br/>
<code>-n</code>表示能创建多少个锁。假定你有2个数据分区，那就需要2个锁。
注意，一旦初始化后，不能再增加锁的数量（暂时我没有看到如何增加）。因此要考虑数据分区的扩展性，所以建议多初始化几个锁。</p>

<h3>测试分区</h3>

<p><a href="http://www.linux-ha.org/wiki/Sfex_(resource_agent)" title="Shared Disk EXclusiveness control Program">SFEX</a>提供了<code>sfex_state</code>指令来测试分区信息是否有效，指令使用及输出结果如下：</p>

<pre><code>    # sfex_stat -i 1 /dev/sdb1
    control data:
    magic: 0x53, 0x46, 0x45, 0x58
    version: 1
    revision: 3
    blocksize: 512
    numlocks: 3
    lock data #1:
    status: lock
    count: 393
    nodename: tsd1
    status is UNLOCKED
</code></pre>

<p><code>-i 1</code>表示锁的位置，从1开始，以此类推。</p>

<h3>配置HA</h3>

<p>这个步骤就和平常没有什么区别了，每一个<code>Filesystem</code>资源，对应一个<code>sfex</code>资源，比如我测试的环境的<code>crm configure show</code>的部分结果如下：</p>

<pre><code>    primitive prmData ocf:heartbeat:Filesystem \
        params device="/dev/sdb2" fstype="ext4" directory="/misc" \
        op monitor interval="3" \
        meta target-role="Started"
    primitive prmEx ocf:heartbeat:sfex \
        params collision_timeout="1" lock_timeout="70" monitor_interval="10" \
        index="1" device="/dev/sdb1"  monitor interval="10"
    primitive sfex2 ocf:heartbeat:sfex \
        params collision_timeout="5" lock_timeout="20" index="2" device="/dev/sdb1" \
        op monitor interval="10"
    primitive sfex2data ocf:heartbeat:Filesystem \
        params device="/dev/sdb3" fstype="ext4" directory="/sfex2data" \
        op monitor interval="10"
    group grp1 prmEx prmData
    group grp2 sfex2 sfex2data
</code></pre>

<p><code>prmEx</code> 和 <code>prmData</code> 是两个<code>sfex</code>资源，使用的锁位置分别是1和2。<br/>
当前HA状态信息如下：</p>

<pre><code>    Last updated: Thu Jan 12 18:07:11 2012
    Last change: Fri Jan 13 00:27:19 2012
    Stack: Heartbeat
    Current DC: tsd1 (424e04a8-0b7c-4d6a-85cb-f005cbd1702d) - partition with quorum
    Version: 1.1.6-1.fc15-b379478e0a66af52708f56d0302f50b6f13322bd
    2 Nodes configured, unknown expected votes
    4 Resources configured.
    ============

    Online: [ wgzhao-nb tsd1 ]

    Resource Group: grp1
         prmEx  (ocf::heartbeat:sfex):  Started tsd1
         prmData    (ocf::heartbeat:Filesystem):    Started tsd1
    Resource Group: grp2
         sfex2  (ocf::heartbeat:sfex):  Started wgzhao-nb
         sfex2data  (ocf::heartbeat:Filesystem):    Started wgzhao-nb
</code></pre>

<h3>心跳失效模拟测试</h3>

<p>当前<code>prmEx</code>的锁所有权在<code>tsd1</code>节点上，<code>sfex2</code>在<code>wgzhao-nb</code>上。我们做一个手工模拟心跳失效测试，就是我们希望手工在<code>wgzhao-nb</code>上获得<code>prmEx</code>的锁。</p>

<p>首先导出OCF的相关环境变量</p>

<pre><code>    export OCF_ROOT=/usr/lib/ocf
    export OCF_RESKEY_device=/dev/sdb1
    export OCF_RESKEY_index=1
    ./sfex start
    sfex[11849]: INFO: sfex_daemon: starting...
    sfex[11849]: DEBUG: sfex_monitor: started...
    sfex[11849]: DEBUG: sfex_monitor: complete. sfex_daemon is not running.
    sfex[11849]: ERROR: sfex_daemon failed to start.
</code></pre>

<p>从上述结果可以看出，如果心跳出现了故障，尝试在两个节点同时启动时，<code>sfex</code>报错，返回值为1，表示请求锁超时，这表明当一个节点已经获得所有权后，另外一个节点无法获得锁。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL查询工具网站的部署]]></title>
    <link href="http://wgzhao.github.io/2011/09/20/clone-explain-depesz-com-website/"/>
    <updated>2011-09-20T00:00:00+08:00</updated>
    <id>http://wgzhao.github.io/2011/09/20/clone-explain-depesz-com-website</id>
    <content type="html"><![CDATA[<p>从 IRC #postgresql 频道了解到一个网站: <a href="http://explain.depesz.com">http://explain.depesz.com</a> 其口号是：</p>

<blockquote><p>A tool for finding a real cause for slow queries</p></blockquote>

<p>方法是粘贴你的 <code>explain
sql</code> 语句结构。
他可以根据结果生成HTML格式的解释页面，其中用不同颜色来标识子语句所占用的资源情况，其中颜色越深，标识所占用的资源越多。<br/>
同时它还给出了两张统计列表，一张是按照索引类型来统计占用的时间，及比率；另外一种是根据SQL语句中涉及到的表来统计查询每张表所占用的时间及比率。
不仅如此，这个网站代码还是开源的，托管在github上。地址为：
<a href="https://github.com/depesz/explain.depesz.com">https://github.com/depesz/explain.depesz.com</a></p>

<p>下面是搭建过程：</p>

<!--more-->


<ol>
<li>环境：Debian unstable 64bit</li>
<li>首先安装网站代码以来的perl框架mojolicious，可以从<a href="http://www.mojolicious.org/">http://www.mojolicious.org/</a>
下载源代码编译安装。不过Debian的源里有这个软件，可以直接通过<code>sudo apt-get install mojolicious</code> 来安装。
2)从<a href="http://backpan.perl.org/authors/id/D/DE/DEPESZ/Pg-Explain-0.61.tar.gz">http://backpan.perl.org/authors/id/D/DE/DEPESZ/Pg-Explain-0.61.tar.gz</a>
下载分析explain SQL的perl模块，这个模块也是网站作者编写的。下载解压，执行<code>perl Build.pl</code>
，如果提示有模块没有安装，则执行 <code>./Build installdeps</code> 而后执行 <code>./Build install</code> 即可。</li>
<li><p>下载explain.depesze.com的源代码</p>

<pre><code> cd /home/wgzhao/websites/
 git clone https://github.com/depesz/explain.depesz.com.git  explain
</code></pre></li>
<li><p>网站默认使用的是postgresql数据库，我们修改
<code>explain.json</code>文件中关于database区域的相关信息。保证perl能正确连接上数据库。</p></li>
<li><p>用psql连接postgresql，创建<code>explain.json</code>里设置的数据库名，并导入<code>sql/create.sql</code>文件。</p></li>
<li><p>执行<code>morbo  --verbose ./explain.pl</code> 根据提示，如果报一些perl模块找不到，先安装这些模块。直到上述指令出现类似下面的结果：<br/>
     [Tue Sep 20 18:17:37 2011]<br/>
     [info] Server listening (<a href="http://*:3000">http://*:3000</a>) Server available at <a href="http://127.0.0.1:3000.">http://127.0.0.1:3000.</a></p></li>
<li>打开浏览器，访问 <a href="http://127.0.0.1:3000">http://127.0.0.1:3000</a>，看看是不是获得了和<a href="http://explain.depesz.com/">http://explain.depesz.com/</a> 一样的效果？</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[IP地址归属地查询]]></title>
    <link href="http://wgzhao.github.io/2011/07/20/ip-location-search/"/>
    <updated>2011-07-20T00:00:00+08:00</updated>
    <id>http://wgzhao.github.io/2011/07/20/ip-location-search</id>
    <content type="html"><![CDATA[<p>好吧，我承认，这是一个很不靠谱的标题，也是很欧特曼的标题了，只是那些很潮的人们可以理解在offline的情况下，*nix使用者们该如何很好的做到标题的功能呢？查询了一番，没有什么看上去很好的办法，于是自己根据纯真IP地址库，写了一个Python脚本，效率估计够呛，不过能正确查询到相关信息。
你要做的是首先搜索一把纯真地址库，如何下载（一般是<code>qqwry.dat</code>)，而后copy我下面的代码，保存为.py文件，如何就可以获得类似我下面的这样的结果了：</p>

<p><code>bash
localhost:bin wgzhao$ ./ipsc.py 219.90.126.44  
Country:   香港  Local:   第一线有限公司
</code></p>

<p>完整代码如下：</p>

<!--more-->


<p>File /Users/wgzhao/Codes/wgzhao.github.io/source/downloads/code/ipsc.py could not be found</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[快速制作一个虚假deb格式软件包]]></title>
    <link href="http://wgzhao.github.io/2011/03/18/how-to-build-a-fake-deb-package-quickly/"/>
    <updated>2011-03-18T00:00:00+08:00</updated>
    <id>http://wgzhao.github.io/2011/03/18/how-to-build-a-fake-deb-package-quickly</id>
    <content type="html"><![CDATA[<p>把上面的代码保存为<code>dummy.c</code>。而后使用<code>autoscan</code>命令来粗昂间一个<code>configure</code>模板文件，命令如下</p>

<pre><code>$ autoscan 
$ ls
autoscan.log  configure.scan  dummy.c
</code></pre>

<p>将生成的<code>configure.scan</code>文件保存为<code>configure.in</code>，并进行修改，只用保留下面几行内容就行了，我在文件里注释说明</p>

<!--more-->


<pre><code>AC_PREREQ([2.67])
#定义包的名字，版本以及bug发布地址
AC_INIT(dummy, 2009-10, fake@example.com)
#传递给automake的参数
AM_INIT_AUTOMAKE(dummy,2009-10)
AC_CONFIG_SRCDIR([dummy.c])
AC_CONFIG_HEADERS([config.h])
AC_PROG_CC
#输出文件名
AC_OUTPUT(Makefile)
</code></pre>

<p>上面的版本号可以随意定义，但是为了和我们当前系统获取的真实的<code>texlive-base</code>包版一致，我们取的一样。我们可以先通过下面的指令获得该包的版本</p>

<pre><code>$ apt-cache show texlive-base |grep '^Version'
Version: 2009-10
</code></pre>

<p>执行<code>aclocalhe</code>和<code>autoconf</code>，生成<code>confiugre</code>文件</p>

<pre><code>$ aclocal
$ autoconf 
$ ls
autom4te.cache  autoscan.log  configure  configure.in  dummy.c
</code></pre>

<p>新建<code>Makefile.am</code>文件，再由<code>automake</code>工具根据所写的<code>Makefile.am</code>文件来自动生成<code>Makefile.in</code>文件。
<code>Makefile.am</code>文件一般定义自己的软件最后生成的可执行程序名字、需要连接的库等，这里只有一个c文件，因此<code>Makefile.am</code>就相当简单了</p>

<pre><code>$ cat Makefile.am 
bin_PROGRAMS=dummy
dummy_SOURCES=dummy.c
</code></pre>

<p>注意上面的最后一行，dummy是依赖第一行的设置，如果第一行最后设置为foo,那么第二行就应该是<code>foo_SOURCES</code>
好了，现在有了Makefile.am了，我们可以创建<code>Makefile.in</code>文件了,不过创建<code>Makefile.in</code>之前，我们还需要创建<code>automake</code>必须要的一些文件，然后再执行她</p>

<pre><code>$ touch NEWS README AUTHORS ChangeLog
$ automake --add-missing
$ ls
aclocal.m4      ChangeLog      configure.in  INSTALL      missing
AUTHORS         config.log     COPYING       install-sh   NEWS
autom4te.cache  config.status  depcomp       Makefile.am  README
autoscan.log    configure      dummy.c       Makefile.in
</code></pre>

<p>以上会给出一些警告，因为我们缺少一个软件源代码一般都需要的INSTALL,README等文件。当然你可以touch这些，或者对这些直接飘过，反正我们这个包只是用来欺骗apt的。
接下来的步骤我们就很熟悉了，就是<code>./configure &amp;&amp; make</code> 这个套路了，我们来执行它吧：</p>

<pre><code>$ automake
$ ./configure 
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking for style of include used by make... GNU
checking dependency style of gcc... gcc3
configure: creating ./config.status
config.status: creating Makefile
config.status: executing depfiles commands
$ make
gcc -DPACKAGE_NAME=\"dummy\" -DPACKAGE_TARNAME=\"dummy\" -DPACKAGE_VERSION=\"2009-10\" -DPACKAGE_STRING=\"dummy\ 2009-10\" -DPACKAGE_BUGREPORT=\"fake@example.com\" -DPACKAGE_URL=\"\" -DPACKAGE=\"dummy\" -DVERSION=\"2009-10\" -I.     -g -O2 -MT dummy.o -MD -MP -MF .deps/dummy.Tpo -c -o dummy.o dummy.c
mv -f .deps/dummy.Tpo .deps/dummy.Po
gcc  -g -O2   -o dummy dummy.o  
$ ls
aclocal.m4      ChangeLog      configure.in  dummy.c     Makefile     NEWS
AUTHORS         config.log     COPYING       dummy.o     Makefile.am  README
autom4te.cache  config.status  depcomp       INSTALL     Makefile.in
autoscan.log    configure      dummy         install-sh  missing
</code></pre>

<p>好了，make成功了，如果仅仅是安装，我们执行<code>make install</code>
就好了，但是我们的目的是创建一个deb包，虽然我们可以按照Debian的New Maintainer
Guide一步一步制作deb包，详细的过程请参照：
<a href="http://www.debian.org/doc/maint-guide/">http://www.debian.org/doc/maint-guide/</a>
但是我们为了快速创建deb包，还是利用checkinstall这个工具好了。</p>

<pre><code>$ checkinstall -D -y --install=no --pkgname=texlive-base --pkgversion=2009-10

checkinstall 1.6.2, Copyright 2009 Felipe Eduardo Sanchez Diaz Duran

...... .....
*******************************************************

 Done. The new package has been saved to

 /var/tmp/texlive-base/texlive-base_2009-10-1_i386.deb
 You can install it in your system anytime using: 

      dpkg -i texlive-base_2009-10-1_i386.deb

***********************************************************
</code></pre>

<p>看到最好了吧，我们就得到了<code>texlive-base_2009-10-1_i386.deb</code>包了，这个包，没有任何依赖关系，你可以直接安装。安装后，再执行</p>

<pre><code>$sudo apt-get install texworks
</code></pre>

<p>从列出的依赖关系中，你就发现少了texlive-base包了。 如果你依赖的包很多，那么我们可以将上述过程自动化，非常方便。</p>
]]></content>
  </entry>
  
</feed>
