<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Linux技术 | Linux系统管理]]></title>
  <link href="http://wgzhao.github.io//categories/linuxji-zhu/atom.xml" rel="self"/>
  <link href="http://wgzhao.github.io/"/>
  <updated>2014-03-16T20:33:53+08:00</updated>
  <id>http://wgzhao.github.io/</id>
  <author>
    <name><![CDATA[wgzhao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Linux下的一些I/O统计工具]]></title>
    <link href="http://wgzhao.github.io/2012/08/22/some-way-to-io-statistics-on-linux/"/>
    <updated>2012-08-22T10:25:00+08:00</updated>
    <id>http://wgzhao.github.io/2012/08/22/some-way-to-io-statistics-on-linux</id>
    <content type="html"><![CDATA[<p>作为一个Linux系统管理员，统计各类IO是一项必不可少的工作。其统计工具中iostat显然又是最重要的一个统计手段。但是这里iostat不是本文的重点，因为这个工具的使用在网络上已经有大量的教程，可以供大家参考。这里主要是想介绍一些其他统计工具以来满足不同的需求。</p>

<h3>iostat</h3>

<p>iostat的功能异常强大，输出项也特别多，比如下面这个例子：</p>

<p>```
Device: rrqm/s  wrqm/s  r/s     w/s    rkB/s    wkB/s    avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</p>

<p>sda     0.00     0.50  173.50   73.50  3076.00   604.00    29.80   149.93    676.58   74.36 2098.15  4.05 100.00
```</p>

<p>其各项的含义分别是：</p>

<!--more-->


<ul>
<li>rrqm/s:       每秒进行 merge 的读操作数目.即 delta(rmerge)/s</li>
<li>wrqm/s:  每秒进行 merge 的写操作数目.即 delta(wmerge)/s</li>
<li>r/s:               每秒完成的读 I/O 设备次数.即 delta(rio)/s</li>
<li>w/s:             每秒完成的写 I/O 设备次数.即 delta(wio)/s</li>
<li>rsec/s:        每秒读扇区数.即 delta(rsect)/s</li>
<li>wsec/s:      每秒写扇区数.即 delta(wsect)/s</li>
<li>rkB/s:          每秒读K字节数.是 rsect/s 的一半,因为每扇区大小为512字节.(需要计算)</li>
<li>wkB/s:    每秒写K字节数.是 wsect/s 的一半.(需要计算)</li>
<li>avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区).delta(rsect+wsect)/delta(rio+wio)</li>
<li>avgqu-sz: 平均I/O队列长度.即 delta(aveq)/s/1000 (因为aveq的单位为毫秒).</li>
<li>await:        平均每次设备I/O操作的等待时间 (毫秒).即 delta(ruse+wuse)/delta(rio+wio)</li>
<li>svctm:       平均每次设备I/O操作的服务时间 (毫秒).即 delta(use)/delta(rio+wio)</li>
<li>%util:          一秒中有百分之多少的时间用于 I/O 操作,或者说一秒中有多少时间 I/O 队列是非空的.即 delta(use)/s/1000 (因为use的单位为毫秒)</li>
</ul>


<p>如果 <code>%util</code> 接近 100%,说明产生的I/O请求太多,I/O系统已经满负荷,该磁盘可能存在瓶颈.</p>

<p>idle小于70% IO压力就较大了,一般读取速度有较多的wait.</p>

<p>同时可以结合<code>vmstat</code>查看查看b参数(等待资源的进程数)和wa参数(IO等待所占用的CPU时间的百分比,高过30%时IO压力高)</p>

<p>另外 <code>await</code> 的参数也要多和 <code>svctm</code> 来参考。差的过高就一定有 IO 的问题.</p>

<p><code>avgrq-sz</code> 也是个做 IO 调优时需要注意的地方,这个就是直接每次操作的数据的大小,如果次数多,但数据拿的小的话,其实 IO 也会很小.如果数据拿的大,才IO 的数据会高.也可以通过 <code>avgqu-sz × ( r/s or w/s ) = rsec/s or wsec/s</code>.也就是讲,读定速度是这个来决定的.</p>

<p><code>svctm</code> 一般要小于 <code>await</code> (因为同时等待的请求的等待时间被重复计算了),<code>svctm</code> 的大小一般和磁盘性能有关,CPU/内存的负荷也会对其有影响,请求过多也会间接导致 <code>svctm</code> 的增加.<code>await</code> 的大小一般取决于服务时间(<code>svctm</code>) 以及 I/O 队列的长度和 I/O 请求的发出模式.如果 svctm 比较接近 await,说明 I/O 几乎没有等待时间；如果 await 远大于 svctm,说明 I/O 队列太长,应用得到的响应时间变慢,如果响应时间超过了用户可以容许的范围,这时可以考虑更换更快的磁盘,调整内核 <code>elevator</code> 算法,优化应用,或者升级 CPU.</p>

<p> 队列长度(<code>avgqu-sz</code>)也可作为衡量系统 I/O 负荷的指标,但由于 <code>avgqu-sz</code> 是按照单位时间的平均值,所以不能反映瞬间的 I/O 洪水.</p>

<p>有时间的话，我会单独写几个帖子来说说<code>iostat</code>。</p>

<h3>iodump</h3>

<p><a href="http://aspersa.googlecode.com/svn/trunk/iodump">iodump</a> 是一个统计每一个进程(线程)所消耗的磁盘I/O工具。这个一个perl脚本，其原理时打开有关I/O的内核记录消息开关，而后读取消息然后分析输出。简单使用步骤如下：</p>

<p>首先下载这个工具</p>

<p><code>wget http://aspersa.googlecode.com/svn/trunk/iodump</code></p>

<p>然后打开有关I/O内核消息的开关</p>

<p><code>echo 1 &gt;/proc/sys/vm/block_dump</code></p>

<p>上述开关打开后，内核会记录下每一个I/O操作的消息。我们只需要定时获取并分析就好了，比如下面这样</p>

<p><code>while true; do sleep 1; dmesg -c ; done |perl iodump</code></p>

<p>等待一段时间，然后通过<code>ctrl+c</code>来结束上述脚本，你将获得下面类似的信息:</p>

<p><code>
TASK                   PID      TOTAL       READ      WRITE      DIRTY DEVICES
postgres              5799       1919       1919          0          0 sda7
jbd2/sda7-8           1572         35          0         35          0 sda7
jbd2/sda2-8            250         32          0         32          0 sda2
flush-8:0             2229         31          0         31          0 sda2, sda7
postgres              4308          2          0          2          0 sda7
bash                  5804          1          0          1          0 sda2
</code>
上述输出的单位为块(block)，每块的大小取决于创建文件系统时指定的块大小。比如我这个里的sda7的block大小是1KB。</p>

<h3>iotop</h3>

<p><a href="http://guichaz.free.fr/iotop/">iotop</a>是一个Python编写的工具，有类似<code>top</code>工具的UI，包括一些参数也和<code>top</code>类似。不过它对系统有一些要求，分别是：</p>

<ol>
<li>Python ≥ 2.5 or Python ≥  2.4 with the ctypes module</li>
<li>Kernel ≥  2.6.20</li>
<li>Kernel uses options:

<ol>
<li>TASK_DELAY_ACCT</li>
<li>CONFIG_TASKSTATS</li>
<li>TASK_IO_ACCOUNTING</li>
<li>CONFIG_VM_EVENT_COUNTERS</li>
</ol>
</li>
</ol>


<p>如果是基于RPM包的系统，可以直接下载编译好的二进制包(<a href="http://guichaz.free.fr/iotop/files/iotop-0.4.4-1.noarch.rpm">here</a>)或者二进制源代码包(<a href="http://guichaz.free.fr/iotop/files/iotop-0.4.4-1.src.rpm">here</a>)</p>

<p>如果是Debian/Ubuntu系统，直接使用</p>

<p><code>sudo apt-get install iotop</code></p>

<p>即可（不得不说，Debian系统提供的软件真的是相当丰富呀)，其他系统则可以通过下面的指令下载源代码，然后编译</p>

<p><code>git clone git://repo.or.cz/iotop.git</code></p>

<p>具体的使用方法可以参考iotop(8)手册，下面是在我机器上的一个显示：</p>

<p><code>
iotop -o -u wgzhao
Total DISK READ:       2.15 M/s | Total DISK WRITE:    1601.15 K/s
  TID  PRIO  USER     DISK READ  DISK WRITE  SWAPIN      IO    COMMAND
 5984 be/4 wgzhao      2.15 M/s   70.55 K/s  0.00 % 83.67 % postgres: wgzhao pgbench [local] UPDATE
 4305 be/4 wgzhao      0.00 B/s  227.34 K/s  0.00 %  0.00 % postgres: writer process
 4308 be/4 wgzhao      0.00 B/s   90.15 K/s  0.00 %  0.00 % postgres: stats collector process
</code></p>

<h3>iopp</h3>

<p><a href="https://github.com/markwkm/iopp">iopp</a>是另外一个统计每一个进程I/O的工具，使用C语言编写，理论上应该比上述两个重狙效率都要高。<br/>
安装方法很简单，首先通过下面的指令下载源代码:</p>

<p><code>git://github.com/markwkm/iopp.git</code></p>

<p>然后分别通过下面的指令编译安装</p>

<p><code>
cmake CMakeLists.txt
make
make install DESTDIR=/usr
</code></p>

<p>下面是一个使用例子</p>

<p><code>
iopp -i -c 2
  pid    rchar    wchar    syscr    syscw   rbytes   wbytes  cwbytes command
 2144        0      296       40        8        0        0        0 /usr/sbin/LCDd
 2284        0        0        2        0        0        0        0 ha_logd: read process
 2299        0        0        2        0        0        0        0 ha_logd: write process
 2520        3        3        3        3        0        0        0 /usr/lib/virtualbox/vboxwebsrv
 2599        2        2        2        2        0        0        0 /usr/lib/virtualbox/VBoxSVC
 2675        0        0        1        0        0        0        0 runsvdir
 3177       16       16        4        2        0        0        0 /usr/bin/gnome-shell
 3192       16       16        4        2        0        0        0 nautilus
 3305      180      340      100       60        0        0        0 /usr/lib/icedove/icedove-bin
 3623     1393     1440        1        1        0        0        0 sshd: wgzhao@pts/0
 4305        0  4603904        0      562        0  4603904        0 postgres: writer process   
 6257  2064384  1892352      252      215  3719168   139264        0 postgres: wgzhao pgbench [local] UPDATE
</code></p>

<p>上述输出的各项含义是：</p>

<ul>
<li>pid 进程ID</li>
<li>rchar 将要从磁盘读取的字节数</li>
<li>wchar 已经写入或应该要写入磁盘的字节数</li>
<li>syscr 读I/O数</li>
<li>syscw 写I/O数</li>
<li>rbytes 真正从磁盘读取的字节数</li>
<li>wbytes 真正写入到磁盘的字节数</li>
<li>cwbytes 因为清空页面缓存而导致没有发生操作的字节数</li>
<li>command 执行的命令</li>
</ul>


<p>其中<code>rbytes</code>,<code>wbytes</code>,<code>cwbytes</code>会因给出<code>-k</code>或者<code>-m</code>参数，而显示为<code>rkb</code>,<code>wkb</code>,<code>cwkb</code>或<code>rmb</code>,<code>wmb</code>,<code>cwmb</code>。<code>command</code>一列如果给出<code>-c</code>的参数则显示完整的命令名而不仅仅只是命令本身。<br/>
这些参数的使用和<code>top</code>类似。</p>

<p>更具体的可以参考iopp(8)手册。</p>

<h3>dstat</h3>

<p><a href="http://dag.wieers.com/home-made/dstat/">dstat</a> 号称各种资源统计工具，其目的是想替代<code>vmstat</code>,<code>iostat</code>,<code>netstat</code>,<code>ifstat</code>等各种单一统计工具，从而做到<code>All in one</code>。 dstat用Python语言编写。</p>

<p>dstat能够清晰显示每列的信息，特别是单位及大小很明确，不会在单位换算上犯迷糊和失误。最重要的是，因为它是基于模块化设计，因此我们可以很容易的写一个插件来收集我们需要的统计信息。</p>

<p>另外，dstat的输出还可以导出为<code>CSV</code>格式文件，从而可以在电子表格工具里分方便的生成统计图形。</p>

<p>目前dstat的插件已经相当多了，这是我机器上目前的输出:</p>

<p>```
$ dstat  &mdash;list
internal:</p>

<pre><code>aio, cpu, cpu24, disk, disk24, disk24old, epoch, fs, int, int24, io, ipc, load, lock, mem, net, 
page, page24, proc, raw, socket, swap, swapold, sys, tcp, time, udp, unix, vm
</code></pre>

<p>/usr/share/dstat:</p>

<pre><code>battery, battery-remain, cpufreq, dbus, disk-tps, disk-util, dstat, dstat-cpu, dstat-ctxt, 
dstat-mem, fan, freespace, gpfs, gpfs-ops, helloworld, innodb-buffer, innodb-io, innodb-ops, lustre, 
memcache-hits, mysql-io, mysql-keys, mysql5-cmds, mysql5-io, mysql5-keys, net-packets, nfs3, 
nfs3-ops, nfsd3, nfsd3-ops, ntp, postfix, power, proc-count, qmail, rpc, rpcd, sendmail, snooze, 
squid, test, thermal, top-bio, top-bio-adv, top-childwait, top-cpu, top-cpu-adv, top-cputime, 
top-cputime-avg, top-int, top-io, top-io-adv, top-latency, top-latency-avg, top-mem, top-oom, utmp, 
vm-memctl, vmk-hba, vmk-int, vmk-nic, vz-cpu, vz-io, vz-ubc, wifi
</code></pre>

<p>```</p>

<p>下面给出几个使用的列子（实际输出是带彩色的，很容易识别）</p>

<p>dstat的缺省输出</p>

<p><code>
wgzhao-nb:~# dstat
You did not select any stats, using -cdngy by default.
----total-cpu-usage---- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai hiq siq| read  writ| recv  send|  in   out | int   csw
  2   1  87  10   0   0| 816k  385k|   0     0 |   0     0 |2279  7048
  5   1  78  16   0   0|2600k    0 | 140B  940B|   0     0 |5952    13k
  5   3  80  12   0   0|2896k  182k|  70B  358B|   0     0 |6074    14k
  4   2  78  16   0   0|2724k    0 |  70B  374B|   0     0 |5703    15k
  4   2  81  14   0   0|3008k    0 |  70B  358B|   0     0 |5924    13k
  5   1  80  14   0   0|1976k   17k|  70B  358B|   0     0 |5819    13k
  5   2  79  14   0   0|2056k    0 | 198B  374B|   0     0 |5618    13k
  4   2  79  15   0   0|2416k    0 |  70B  358B|   0     0 |5866    15k
  5   2  78  15   0   0|2528k    0 |  70B  358B|   0     0 |6356    14k
  5   2  78  16   0   0|2288k    0 |  70B  358B|   0     0 |6515    15k
  5   2  79  14   0   0|2656k 8192B|  70B  358B|   0     0 |6490    15k
  3   2  81  13   0   0|2296k    0 |  70B  374B|   0     0 |5573    15k
  4   3  76  17   0   1|2224k    0 |  70B  358B|   0     0 |5366    12k
  5   1  81  13   0   0|2208k    0 | 508B  358B|   0     0 |5403    13k
  4   2  79  15   0   0|2024k  182k|  70B  358B|   0     0 |5583    13k
  5   2  79  15   0   0|2148k   17k| 186B  490B|   0     0 |5400    12k
</code></p>

<p>指定需要显示的列</p>

<p><code>
wgzhao-nb:~# dstat  -c --top-cpu -d --top-bio --top-latency
Module dstat_top_latency failed to load. (Kernel has no scheduler statistics, use at least 2.6.12)
----total-cpu-usage---- -most-expensive- -dsk/total- ----most-expensive----
usr sys idl wai hiq siq|  cpu process   | read  writ|  block i/o process   
  2   1  87  10   0   0|gnome-shell  0.7| 826k  384k|postgres    692k   52k
  4   2  79  16   0   0|postgres: wgz3.0|1744k  776k|postgres: w1744k   72k
  5   3  78  15   0   0|postgres: wgz5.0|3120k    0 |postgres: w3064k  136k
  6   2  73  19   0   0|postgres: wgz4.2|2608k  285k|postgres: w2608k  136k
  4   2  77  17   0   0|postgres: wgz3.5|2112k  848k|postgres: w2112k   88k
  3   2  71  25   0   0|postgres: wgz2.0| 944k 1049k|postgres: w 936k   48k
  3   2  58  37   0   0|postgres: wgz2.0| 920k 2070k|postgres: w 928k   64k
  3   2  62  34   0   0|postgres: wgz2.2|1496k  992k|postgres: w1608k   72k
  3   2  56  38   0   0|postgres: wgz3.0|1840k  645k|postgres: w1856k   88k
  3   2  78  17   0   0|postgres: wgz3.0|1420k 1200k|postgres: w1292k   80k
  5   2  80  12   0   1|postgres: wgz4.2|2628k    0 |postgres: w2636k  112k
  4   3  69  25   0   0|postgres: wgz3.8|2168k  576k|postgres: w2224k  104k
</code></p>

<p>指定需要显示的列，并同时将结果导出到文件</p>

<p><code>
wgzhao-nb:~# dstat  --disk --mem --proc --io --sys --filesystem --tcp --vm --output dstat.csv
-dsk/total- ------memory-usage----- ---procs--- --io/total- ---system-- --filesystem- ----tcp-sockets---- -----virtual-memory----
 read  writ| used  buff  cach  free|run blk new| read  writ| int   csw |files  inodes|lis act syn tim clo|majpf minpf alloc  free
 844k  404k| 829M 19.4M 2920M  124M|  0 0.0 0.7|47.5  38.4 |2336  7185 | 4928  12286 | 11   3   0   0   2|   1   620   602   605
2128k 1526k| 828M 19.4M 2915M  130M|  0 2.0   0| 111   157 |4588    14k| 4928  12285 | 11   3   0   0   2|   0  1859   995  2278
 920k 2151k| 826M 19.4M 2917M  129M|  0 2.0   0|52.0   237 |3091  7540 | 4928  12284 | 11   3   0   0   2|   0  4448  2330  2144
2124k 1003k| 826M 19.4M 2921M  126M|1.0 1.0   0| 135   106 |4705    14k| 4928  12284 | 11   3   0   0   2|   0   331   865     1
2344k 1024k| 826M 19.4M 2924M  122M|1.0 2.0   0| 121   118 |4074    13k| 4928  12284 | 11   3   0   0   2|   0   249   953     1
1572k 1624k| 827M 19.4M 2926M  120M|1.0 2.0   0|87.0   190 |3231    11k| 4928  12284 | 11   3   0   0   2|   0    98   530     1
 916k  788k| 827M 19.4M 2928M  119M|  0 2.0   0|68.0  92.0 |3452  8709 | 4928  12284 | 11   3   0   0   2|   0   128   383     4
2452k 1665k| 826M 19.4M 2931M  116M|1.0 1.0   0| 132   197 |4779    14k| 4928  12284 | 11   3   0   0   2|   0   208   822     1
1552k 1328k| 827M 19.4M 2933M  114M|  0 2.0   0|97.0   156 |3762  9117 | 4928  12284 | 11   3   0   0   2|   0   133   473     1
1192k 2024k| 827M 19.4M 2934M  112M|  0 2.0   0|81.0   239 |4068    11k| 4928  12284 | 11   3   0   0   2|   0   135   414     2
2668k  584k| 827M 19.4M 2937M  109M|  0 2.0   0| 148  71.0 |4415    10k| 4928  12284 | 11   3   0   0   2|   0   174   870     4
1712k  960k| 827M 19.4M 2940M  106M|  0 2.0   0| 122   113 |4454    14k| 4928  12284 | 11   3   0   0   2|   0   182   616     2
</code></p>

<p>更详细的用法，可以参考dstat(1)手册</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL查询工具网站的部署]]></title>
    <link href="http://wgzhao.github.io/2011/09/20/clone-explain-depesz-com-website/"/>
    <updated>2011-09-20T00:00:00+08:00</updated>
    <id>http://wgzhao.github.io/2011/09/20/clone-explain-depesz-com-website</id>
    <content type="html"><![CDATA[<p>从 IRC #postgresql 频道了解到一个网站: <a href="http://explain.depesz.com">http://explain.depesz.com</a> 其口号是：</p>

<blockquote><p>A tool for finding a real cause for slow queries</p></blockquote>

<p>方法是粘贴你的 <code>explain
sql</code> 语句结构。
他可以根据结果生成HTML格式的解释页面，其中用不同颜色来标识子语句所占用的资源情况，其中颜色越深，标识所占用的资源越多。<br/>
同时它还给出了两张统计列表，一张是按照索引类型来统计占用的时间，及比率；另外一种是根据SQL语句中涉及到的表来统计查询每张表所占用的时间及比率。
不仅如此，这个网站代码还是开源的，托管在github上。地址为：
<a href="https://github.com/depesz/explain.depesz.com">https://github.com/depesz/explain.depesz.com</a></p>

<p>下面是搭建过程：</p>

<!--more-->


<ol>
<li>环境：Debian unstable 64bit</li>
<li>首先安装网站代码以来的perl框架mojolicious，可以从<a href="http://www.mojolicious.org/">http://www.mojolicious.org/</a>
下载源代码编译安装。不过Debian的源里有这个软件，可以直接通过<code>sudo apt-get install mojolicious</code> 来安装。
2)从<a href="http://backpan.perl.org/authors/id/D/DE/DEPESZ/Pg-Explain-0.61.tar.gz">http://backpan.perl.org/authors/id/D/DE/DEPESZ/Pg-Explain-0.61.tar.gz</a>
下载分析explain SQL的perl模块，这个模块也是网站作者编写的。下载解压，执行<code>perl Build.pl</code>
，如果提示有模块没有安装，则执行 <code>./Build installdeps</code> 而后执行 <code>./Build install</code> 即可。</li>
<li><p>下载explain.depesze.com的源代码</p>

<pre><code> cd /home/wgzhao/websites/
 git clone https://github.com/depesz/explain.depesz.com.git  explain
</code></pre></li>
<li><p>网站默认使用的是postgresql数据库，我们修改
<code>explain.json</code>文件中关于database区域的相关信息。保证perl能正确连接上数据库。</p></li>
<li><p>用psql连接postgresql，创建<code>explain.json</code>里设置的数据库名，并导入<code>sql/create.sql</code>文件。</p></li>
<li><p>执行<code>morbo  --verbose ./explain.pl</code> 根据提示，如果报一些perl模块找不到，先安装这些模块。直到上述指令出现类似下面的结果：<br/>
     [Tue Sep 20 18:17:37 2011]<br/>
     [info] Server listening (<a href="http://*:3000">http://*:3000</a>) Server available at <a href="http://127.0.0.1:3000.">http://127.0.0.1:3000.</a></p></li>
<li>打开浏览器，访问 <a href="http://127.0.0.1:3000">http://127.0.0.1:3000</a>，看看是不是获得了和<a href="http://explain.depesz.com/">http://explain.depesz.com/</a> 一样的效果？</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[快速制作一个虚假deb格式软件包]]></title>
    <link href="http://wgzhao.github.io/2011/03/18/how-to-build-a-fake-deb-package-quickly/"/>
    <updated>2011-03-18T00:00:00+08:00</updated>
    <id>http://wgzhao.github.io/2011/03/18/how-to-build-a-fake-deb-package-quickly</id>
    <content type="html"><![CDATA[<p>把上面的代码保存为<code>dummy.c</code>。而后使用<code>autoscan</code>命令来粗昂间一个<code>configure</code>模板文件，命令如下</p>

<pre><code>$ autoscan 
$ ls
autoscan.log  configure.scan  dummy.c
</code></pre>

<p>将生成的<code>configure.scan</code>文件保存为<code>configure.in</code>，并进行修改，只用保留下面几行内容就行了，我在文件里注释说明</p>

<!--more-->


<pre><code>AC_PREREQ([2.67])
#定义包的名字，版本以及bug发布地址
AC_INIT(dummy, 2009-10, fake@example.com)
#传递给automake的参数
AM_INIT_AUTOMAKE(dummy,2009-10)
AC_CONFIG_SRCDIR([dummy.c])
AC_CONFIG_HEADERS([config.h])
AC_PROG_CC
#输出文件名
AC_OUTPUT(Makefile)
</code></pre>

<p>上面的版本号可以随意定义，但是为了和我们当前系统获取的真实的<code>texlive-base</code>包版一致，我们取的一样。我们可以先通过下面的指令获得该包的版本</p>

<pre><code>$ apt-cache show texlive-base |grep '^Version'
Version: 2009-10
</code></pre>

<p>执行<code>aclocalhe</code>和<code>autoconf</code>，生成<code>confiugre</code>文件</p>

<pre><code>$ aclocal
$ autoconf 
$ ls
autom4te.cache  autoscan.log  configure  configure.in  dummy.c
</code></pre>

<p>新建<code>Makefile.am</code>文件，再由<code>automake</code>工具根据所写的<code>Makefile.am</code>文件来自动生成<code>Makefile.in</code>文件。
<code>Makefile.am</code>文件一般定义自己的软件最后生成的可执行程序名字、需要连接的库等，这里只有一个c文件，因此<code>Makefile.am</code>就相当简单了</p>

<pre><code>$ cat Makefile.am 
bin_PROGRAMS=dummy
dummy_SOURCES=dummy.c
</code></pre>

<p>注意上面的最后一行，dummy是依赖第一行的设置，如果第一行最后设置为foo,那么第二行就应该是<code>foo_SOURCES</code>
好了，现在有了Makefile.am了，我们可以创建<code>Makefile.in</code>文件了,不过创建<code>Makefile.in</code>之前，我们还需要创建<code>automake</code>必须要的一些文件，然后再执行她</p>

<pre><code>$ touch NEWS README AUTHORS ChangeLog
$ automake --add-missing
$ ls
aclocal.m4      ChangeLog      configure.in  INSTALL      missing
AUTHORS         config.log     COPYING       install-sh   NEWS
autom4te.cache  config.status  depcomp       Makefile.am  README
autoscan.log    configure      dummy.c       Makefile.in
</code></pre>

<p>以上会给出一些警告，因为我们缺少一个软件源代码一般都需要的INSTALL,README等文件。当然你可以touch这些，或者对这些直接飘过，反正我们这个包只是用来欺骗apt的。
接下来的步骤我们就很熟悉了，就是<code>./configure &amp;&amp; make</code> 这个套路了，我们来执行它吧：</p>

<pre><code>$ automake
$ ./configure 
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking for style of include used by make... GNU
checking dependency style of gcc... gcc3
configure: creating ./config.status
config.status: creating Makefile
config.status: executing depfiles commands
$ make
gcc -DPACKAGE_NAME=\"dummy\" -DPACKAGE_TARNAME=\"dummy\" -DPACKAGE_VERSION=\"2009-10\" -DPACKAGE_STRING=\"dummy\ 2009-10\" -DPACKAGE_BUGREPORT=\"fake@example.com\" -DPACKAGE_URL=\"\" -DPACKAGE=\"dummy\" -DVERSION=\"2009-10\" -I.     -g -O2 -MT dummy.o -MD -MP -MF .deps/dummy.Tpo -c -o dummy.o dummy.c
mv -f .deps/dummy.Tpo .deps/dummy.Po
gcc  -g -O2   -o dummy dummy.o  
$ ls
aclocal.m4      ChangeLog      configure.in  dummy.c     Makefile     NEWS
AUTHORS         config.log     COPYING       dummy.o     Makefile.am  README
autom4te.cache  config.status  depcomp       INSTALL     Makefile.in
autoscan.log    configure      dummy         install-sh  missing
</code></pre>

<p>好了，make成功了，如果仅仅是安装，我们执行<code>make install</code>
就好了，但是我们的目的是创建一个deb包，虽然我们可以按照Debian的New Maintainer
Guide一步一步制作deb包，详细的过程请参照：
<a href="http://www.debian.org/doc/maint-guide/">http://www.debian.org/doc/maint-guide/</a>
但是我们为了快速创建deb包，还是利用checkinstall这个工具好了。</p>

<pre><code>$ checkinstall -D -y --install=no --pkgname=texlive-base --pkgversion=2009-10

checkinstall 1.6.2, Copyright 2009 Felipe Eduardo Sanchez Diaz Duran

...... .....
*******************************************************

 Done. The new package has been saved to

 /var/tmp/texlive-base/texlive-base_2009-10-1_i386.deb
 You can install it in your system anytime using: 

      dpkg -i texlive-base_2009-10-1_i386.deb

***********************************************************
</code></pre>

<p>看到最好了吧，我们就得到了<code>texlive-base_2009-10-1_i386.deb</code>包了，这个包，没有任何依赖关系，你可以直接安装。安装后，再执行</p>

<pre><code>$sudo apt-get install texworks
</code></pre>

<p>从列出的依赖关系中，你就发现少了texlive-base包了。 如果你依赖的包很多，那么我们可以将上述过程自动化，非常方便。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ssh的三板斧]]></title>
    <link href="http://wgzhao.github.io/2011/03/11/ssh-three-kill-features/"/>
    <updated>2011-03-11T00:00:00+08:00</updated>
    <id>http://wgzhao.github.io/2011/03/11/ssh-three-kill-features</id>
    <content type="html"><![CDATA[<p>ssh的功能无比强悍，对于一个<strong>Unix/Linux</strong>而言，只要开放一个ssh服务，就可以轻松，随意，快捷，方便的全盘操控这台机器。相信很多功能大家都很熟悉了，我这里只是想把它的其中三个具有杀手级的功能例举一下：</p>

<h2>端口转发</h2>

<p>端口转发，也就是-L参数的设置。以我的实际例子来说明吧，我在家里上网，设置的是局域网，IP地址是<code>192.168.100.101</code>。公司总部呢，也是用的是局域网地址，<code>172.16.0.0</code>网段。我需要访问公司内部的一台应用服务器，比如<code>172.16.81.111</code>。我该怎么办呢？恰好，公司有一台网关服务器，有两块网卡，一块是设置的公网IP地址，比如<code>219.99.12.23</code>。另外一块网卡，则是公司的内网的IP地址，比如<code>172.16.81.220</code>。这台服务器开启了SSH服务。那么我要做的便是执行下面的指令:</p>

<!--more-->


<p><code>ssh -f -N   -L 8080:172.16.81.111:80 wgzhao@219.99.12.23</code></p>

<p>一旦登陆成功后，在自己的电脑上，打开浏览器，在地址栏，输入<a href="http://localhost:8080">http://localhost:8080</a>，你能看到什么呢？它等价于访问了<a href="http://172.16.81.111/">http://172.16.81.111/</a>。对就是访问了公司总部指定的服务器的WEB服务（假定80端口对应的是WEB服务）。
当然，这里也要注意，如果自己的电脑已经使用了8080端口，则上述指令不会成功，换一个不常用的高端端口吧。
这条指令，基本上可以让你无障碍的访问公司任何服务器的任何服务，甚至是SSH服务（前提是已授权访问）。嗯，想想看，如果上面的指令改成下面这样：</p>

<p><code>ssh -f -N -L 8022:172.16.81.111:22 wgzhao@219.99.12.23</code> 然后你再执行</p>

<p><code>ssh -p 8022  localhost</code>
会是什么样的结果呢？ 此时，你已经通过ssh进入到了公司服务器。我们再进一步，把上述指令改成</p>

<p><code>ssh -X -p 8022 localhost</code></p>

<p>然后执行startx或者gnome-session或者其他的，结果又会是怎样呢？哈哈，其功能仅受限于您的想象力（感谢周立波提供此语句）。</p>

<h2>端口绑定</h2>

<p>端口绑定，也即ssh的-R参数配置。依然举个例子，不在一起的一个朋友，一台机器有些故障需要解决，我需要登陆到他的机器，第一个办法用不上，因为没有一台具有公网IP地址的网关机器。其他办法呢？显然Windows下的那套QQ远程，MSN远程都派不上用场了。怎么办？Linux只有Linux的解决办法。那就是利用可以通过ssh访问的一台有公网IP地址的机器。它可以是VPS，可以是独立主机，总之，只要能够让双方通过ssh访问得到就可以。
首先，让我的朋友执行下面的指令：</p>

<p><code>ssh -qTfN -R 9922:localhost:22  account@222.222.233.212</code></p>

<p>执行成功后。
我在执行下面的指令： <code>ssh account@222.222.233.212</code> 登陆成功后，可以执行</p>

<p><code>netstat -lpnt |grep 9922</code></p>

<p>你应该可以类似下面的输出：</p>

<pre><code>$ netstat -ln |grep 9922 
tcp        0      0  
127.0.0.1:9922              0.0.0.0:*                   
LISTEN       tcp        0      0 ::
1:9922                    :::*                        
LISTEN
</code></pre>

<p>这里的<code>9922</code>端口，实际上就是我朋友电脑上的ssh服务。立马在这台服务器上继续执行下面的指令吧：</p>

<p><code>ssh -p 9922 puser@localhost</code></p>

<p>puser是我朋友电脑上的账号。登陆成功后，我就进入了我朋友的电脑。OK，想干什么都可以做了。
完成后，我朋友只需要把那条包含<code>9922</code>的进程<code>kill</code>就可以了。</p>

<h2>动态端口转发</h2>

<p>动态端口转发，也即-R参数的配置，它的目的是把本地指定的一个端口通过socket模式转发到指定的远程服务器上的特定端口。比如说，我在美国有一个VPS，有用SSH访问功能，如果我在本地执行下面的指令：</p>

<p><code>ssh -D8580 -qnTfN account@myserver.example.com</code></p>

<p>然后呢，比如，打开你的浏览器，设置代理ip地址为<code>127.0.0.1</code>，端口是<code>8580</code>，代理类型是<code>SOCKET5</code>，注意是5，SOCKET4不行（至少我没有测试成功）。设置完成后，虽然访问一些网站，比如<a href="http://blog.wgzhao.com">http://blog.wgzhao.com</a>，看能不能打开。如果能，就表示设置成功了。
然后呢？然后你访问<a href="http://twitter.com">twitter</a>，<a href="http://www.facebook.com">facebook</a>，<a href="http://www.youtube.com">youtube</a>这些根本在实际上就不存在的网站呢？
再然后呢？ 没有了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[在线扩容ext4文件系统]]></title>
    <link href="http://wgzhao.github.io/2011/03/09/online-resizing-ext4-filesystem/"/>
    <updated>2011-03-09T00:00:00+08:00</updated>
    <id>http://wgzhao.github.io/2011/03/09/online-resizing-ext4-filesystem</id>
    <content type="html"><![CDATA[<p>原来一个分区分得太小了（只有5G），等拷贝完数据才知道太小了。于是尝试了扩容的办法。以前对ext3干过这样的事情，看了ext3上的<a href="https://ext4.wiki.kernel.org/index.php/Frequently_Asked_Questions#How_to_online_resize_the_Ext4_filesystem.3F">wiki介绍</a>，得知做法和原来的ext2/ext3一样（看来兼容性还是不错）。下面是我的扩容过程</p>

<p>首先下载你要扩容的分区，这样当然是最保险的，如果你就是不想卸载，只要你别对其做写操作，也没有问题。</p>

<!--more-->


<p>接下来就是用fdisk删除该分区，然后用你期望的大小重建该分区。这里要注意的是，分区的开始扇区一定要和删除前保持一致，否则文件系统就会遭到破坏。下面是我的实际操作过程</p>

<pre><code># fdisk /dev/sda

Command (m for help): p

Disk /dev/sda: 64.4 GB, 64424509440 bytes
255 heads, 63 sectors/track, 7832 cylinders, total 125829120 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00067b51

   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *          63    29302559    14651248+  83  Linux
/dev/sda2        29302784    39061503     4879360   83  Linux

Command (m for help): d
Partition number (1-4): 2

Command (m for help): n
Command action
   e   extended
   p   primary partition (1-4)
p
Partition number (1-4, default 2): 
Using default value 2
First sector (29302560-125829119, default 29302560): 29302784
Last sector, +sectors or +size{K,M,G} (29302784-125829119, default 125829119): +20G

Command (m for help): p

Disk /dev/sda: 64.4 GB, 64424509440 bytes
255 heads, 63 sectors/track, 7832 cylinders, total 125829120 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00067b51

   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *          63    29302559    14651248+  83  Linux
/dev/sda2        29302784    71245823    20971520   83  Linux

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.

WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
The kernel still uses the old table. The new table will be used at
the next reboot or after you run partprobe(8) or kpartx(8)
Syncing disks.
</code></pre>

<p>而后执行下面的指令</p>

<pre><code># partprobe /dev/sda
# e2fsck -f /dev/sda2
e2fsck 1.41.12 (17-May-2010)
Pass 1: Checking inodes, blocks, and sizes
Pass 2: Checking directory structure
Pass 3: Checking directory connectivity
Pass 4: Checking reference counts
Pass 5: Checking group summary information
data: 38934/305216 files (0.1% non-contiguous), 1140469/1219840 blocks
[root@wgzhao-nb wgzhao]# resize2fs /dev/sda2 20G
resize2fs 1.41.12 (17-May-2010)
Resizing the filesystem on /dev/sda2 to 5242880 (4k) blocks.
The filesystem on /dev/sda2 is now 5242880 blocks long.
</code></pre>

<p>我们再挂载上来，得到的就是我期望的大小了（20G）</p>

<pre><code># df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/sda1              14G  6.5G  7.2G  48% /
tmpfs                 1.4G  296K  1.4G   1% /dev/shm
/dev/sda2              20G  4.3G   16G  22% /data
</code></pre>
]]></content>
  </entry>
  
</feed>
